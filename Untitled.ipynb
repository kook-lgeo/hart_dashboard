{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6356df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import requests\n",
    "import json\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "from datetime import datetime,timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b6710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input values\n",
    "param_dict = {\n",
    "    \"fleet_size\" : [50000,10000,1000],\n",
    "    \"mean_dvmt\" : [45,35,25],\n",
    "    \"temp_c\" : [40,30,20,10,0,-10,-20],\n",
    "    \"pev_type\" : ['PHEV20','PHEV50','BEV100','BEV250'],\n",
    "    \"pev_dist\" : ['BEV','PHEV','EQUAL'],\n",
    "    \"class_dist\" : ['Sedan','SUV','Equal'],\n",
    "    \"home_access_dist\" : ['HA100','HA75','HA50',],\n",
    "    \"home_power_dist\" : ['MostL1','MostL2','Equal'],\n",
    "    \"work_power_dist\" : ['MostL1','MostL2','Equal'],\n",
    "    \"pref_dist\" : ['Home60','Home80','Home100'],  \n",
    "    \"res_charging\" : ['min_delay','max_delay','midnight_charge'],\n",
    "    \"work_charging\" : ['min_delay','max_delay']\n",
    "}\n",
    "\n",
    "#Kicks off the run either for just individual scenarios or for scenarios for aggregated temperature profiles (if temp_path is included)\n",
    "#By default, saves weekend/weekday plots for each scenario in the folder this is run from\n",
    "\n",
    "def run(scenario_path, temp_path=\"\", api_key = \"DEMO_KEY\"):\n",
    "\n",
    "    #Ensure scenario_path is valid\n",
    "    try:\n",
    "        pd.read_csv(scenario_path)\n",
    "    except:\n",
    "        scenario_path = input('Enter full file path to scenario csv file: ')\n",
    "    scenario_csv = pd.read_csv(scenario_path)\n",
    "    \n",
    "    if temp_path==\"\":\n",
    "        print(\"Running API without user-defined temperatures...\")\n",
    "        final_result = csv_run(scenario_csv,api_key)\n",
    "        for scenario in final_result.keys():\n",
    "            dow_dict = {}\n",
    "            dow_dict = dow_dict.fromkeys(['weekday_load_profile','weekend_load_profile'])\n",
    "            for dow in dow_dict.keys():\n",
    "                dow_dict[dow] = pd.DataFrame(final_result[scenario][dow].to_list(),index = final_result[scenario].index) \n",
    "                dow_dict[dow].T.to_csv(os.path.join(os.getcwd(),'OutputData','scen'+str(scenario)+\"_\"+dow.split(\"_\")[0].capitalize()+\"_gridLoad.csv\"))\n",
    "            final_result[scenario] = dow_dict\n",
    "\n",
    "    #If we have a temperature csv, read it and pass it to function\n",
    "    else:\n",
    "        temp_csv= pd.read_csv(temp_path)\n",
    "        print(\"Using input csv for temperatures to run the API...\")\n",
    "        temp_csv['date'] = pd.to_datetime(temp_csv['date'])\n",
    "        temp_csv['date'] = temp_csv['date'].dt.date\n",
    "    # Saturday and Sunday are 5 and 6, Monday is 0. <5 is weekday\n",
    "        temp_csv['weekday'] = temp_csv['date'].apply(lambda x: x.weekday())#<5)\n",
    "        temp_csv['temp_c'] = temp_csv['temperature']\n",
    "        temp_csv.drop('temperature',axis = 1,inplace=True)\n",
    "        final_result = temp_run(scenario_csv,temp_csv,api_key)\n",
    "\n",
    "#Plotting and Save CSVs with data\n",
    "    for scenario,row in scenario_csv.iterrows():\n",
    "        if temp_path == \"\":\n",
    "            for dow in final_result[scenario]:\n",
    "                notemp_loadPlotting(final_result[scenario][dow],scenario,dow)\n",
    "        else:\n",
    "            loadPlotting(final_result,scenario)\n",
    "            final_result[scenario].to_csv(os.path.join(os.path.curdir,'OutputData','scen'+str(scenario)+\"_temp_gridLoad.csv\"))\n",
    " \n",
    "\n",
    "\n",
    "#Applies API_Run to every row in temp_csv. This is only run if using a csv with temperature data\n",
    "#Sends in a row based on a single scenario and a set of temperatures (each representing one day or time interval to be averaged)\n",
    "def temp_run(scenario_csv,temp_csv,api_key,smoothing=1):\n",
    "    output_dict = {}\n",
    "    \n",
    "    for scenario_id, scenario_row in scenario_csv.iterrows(): #Each row here represents a particular scenario defined by the user. row index is used as scenario identifier\n",
    "        input_temps = temp_csv['temp_c']\n",
    "        temp_df = temp_csv.assign(**scenario_row)\n",
    "        temp_df['temp_c'] = input_temps #ensure list of temperatures from input csv take priority over temp_c from scenario\n",
    "        temp_df['scenario_id'] = scenario_id\n",
    "        output_df = pd.DataFrame()\n",
    "        \n",
    "    #For each day/temperature in the given csv, run the API. \n",
    "    #output_dict will have one key per scenario, each corresponding to a df with a row per 15 minute time bucket\n",
    "        for temp_id,temp_row in temp_df.iterrows():\n",
    "            result = API_run(temp_row,api_key,smoothing)\n",
    "            result['date'] = temp_row.date\n",
    "            result['time'] = result.index\n",
    "            result['weekday'] = temp_row.weekday\n",
    "            result.index =  [datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\") for x in str(temp_row['date'])+\" \"+result.index]\n",
    "            \n",
    "            \n",
    "        #Smoothing: If day of week is a Saturday or Monday, make sure morning is smoothed with end of previous day\n",
    "        #However, need to ensure the previous day is included in this dataset before smoothing\n",
    "            prev_date = temp_row.date-timedelta(days = 1)\n",
    "            if not output_df.empty:\n",
    "                if (temp_row.weekday==5 or temp_row.weekday==0) & (prev_date in set(output_df.date)):\n",
    "                    try:  \n",
    "                        for charge_type in result.columns[0:6]:\n",
    "                        #Smooth across last hour and first hour between days (8 total values)\n",
    "                            slope_inc = (output_df.loc[str(prev_date)+\" 23:00:00\",charge_type]-result.loc[str(temp_row.date)+\" 0:45:00\",charge_type])/(8)\n",
    "                            if slope_inc == 0:\n",
    "                                pass\n",
    "                            else:\n",
    "                                slope_array = np.arange(output_df.loc[str(prev_date)+\" 23:00:00\",charge_type],result.loc[str(temp_row.date)+\" 0:45:00\",charge_type],-slope_inc)\n",
    "                                slope_array = np.around(slope_array,2)\n",
    "                                output_df.loc[str(prev_date)+\" 23:00:00\":str(prev_date)+\" 23:45:00\",charge_type] = slope_array[:4]\n",
    "                                result.loc[str(temp_row.date)+\" 0:00:00\":str(temp_row.date)+\" 0:45:00\",charge_type] = slope_array[4:]\n",
    "                    except ArithmeticError:\n",
    "                        print(\"slope_inc: \"+str(slope_inc))\n",
    "#                    \n",
    "            output_df = output_df.append(result) \n",
    "        output_dict[scenario_id] = output_df\n",
    "        \n",
    "    return output_dict\n",
    "\n",
    "#Takes in a csv with one row for each parameter that is going to be run\n",
    "def csv_run(input_csv, api_key, smoothing = 1):\n",
    "    output_dict = {}\n",
    "    #output_metadata_dict = {}\n",
    "    for row_id, row in input_csv.iterrows(): #Each row here represents a particular scenario defined by the user. row_idx is used as scenario identifier\n",
    "        for col_idx, val in enumerate(row):\n",
    "            if val not in param_dict[list(param_dict)[col_idx]]:#param_series[col_idx]:\n",
    "                if col_idx==2: #Find closest temperature rather than throwing an error\n",
    "                    nearest_temp = find_nearest(param_dict['temp_c'],val)\n",
    "                    print(\"Scenario \"+str(row_id)+\" temperature: \"+str(val))\n",
    "                    print(\"Nearest value: \"+str(nearest_temp))\n",
    "                    row[col_idx] = nearest_temp\n",
    "                else:\n",
    "                    print(\"Invalid input row index \"+str(row_id)+\", column index \"+str(col_idx)+ (\": \"+param_dict[list(param_dict)[col_idx]]))\n",
    "                break\n",
    "\n",
    "            #Run API_run and append to new series to return with all data\n",
    "            output_dict[row_id] = (API_run(row,api_key,smoothing))\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "#This function is called by temp_apply and returns output from the API based on the row sent by temp_apply\n",
    "def API_run(df_row, api_key, smoothing):  \n",
    "    #Assign values for each parameter- must be in order given in documentation\n",
    "    #if csv_temp parameter is defined, that means it is passed in via csv. Must replace temp_c with that value based on available temps defined for the tool\n",
    "    if len(df_row)==15:\n",
    "        date,weekday,temp_c,fleet_size,mean_dvmt,pev_type,pev_dist,class_dist,home_access_dist,home_power_dist,work_power_dist,pref_dist,res_charging,work_charging,scenario_id = df_row\n",
    "        print(date)\n",
    "    else:\n",
    "        fleet_size,mean_dvmt,temp_c,pev_type,pev_dist,class_dist,home_access_dist,home_power_dist,work_power_dist,pref_dist,res_charging,work_charging = df_row\n",
    "    temp_c = find_nearest(param_dict[\"temp_c\"],temp_c)\n",
    "    #day_of_week and dest_type are used to generate plots- therefore these cannot be set manually\n",
    "    #Generate load profiles for home, public, and work on both weekends and weekdays and for different charger levels according to the selected parameters\n",
    "    base_url = \"\"\"https://developer.nrel.gov/api/evi-pro-lite/v1/daily-load-profile?api_key=%s&\"\"\" %(api_key)\n",
    "    url = base_url+\"\"\"fleet_size=%s&mean_dvmt=%s&temp_c=%s&pev_type=%s&pev_dist=%s&class_dist=%s&home_access_dist=%s&home_power_dist=%s&work_power_dist=%s&pref_dist=%s&res_charging=%s&work_charging=%s\"\"\" \\\n",
    "        %(fleet_size,mean_dvmt,temp_c,pev_type,pev_dist,class_dist,home_access_dist,home_power_dist,work_power_dist,pref_dist,res_charging,work_charging)\n",
    "    url=url.replace(\"\\\\\", \"\")\n",
    "    record_str = requests.get(url).text\n",
    "    record_str = record_str.replace(\"'\", \"\\\"\")\n",
    "    raw_json=json.loads(record_str)\n",
    "    try:\n",
    "        raw_json['results']\n",
    "    except KeyError:\n",
    "        print(\"ERROR:\"+raw_json['error']['code']+\"\\n\")\n",
    "        raise\n",
    "    \n",
    "#if day is a weekday, return the weekday load profile for the day, otherwise return weekend\n",
    "    try:\n",
    "        if weekday<5:\n",
    "            result = pd.DataFrame(raw_json['results']['weekday_load_profile'])\n",
    "        else:\n",
    "            result = pd.DataFrame(raw_json['results']['weekend_load_profile'])\n",
    "            \n",
    "    #Change the index from integers to times throughout the day\n",
    "        result.index = [str(i*timedelta(minutes=15)) for i in range(0,96)]\n",
    "    #If we didn't pass in temperature data, weekday will not be defined\n",
    "    except:\n",
    "        result = pd.DataFrame(raw_json['results'])\n",
    "    return result\n",
    "\n",
    "\n",
    "#Return nearest value in array to single input value\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "##Stack Plot\n",
    "#defaults to plotting one week of data\n",
    "def loadPlotting(result,scenario=0,filename = \"\",week=1):\n",
    "    figlen = 12+len(result[scenario])/1000\n",
    "    fig = plt.figure(figsize = (figlen,7))\n",
    "    ax = plt.axes()\n",
    "    \n",
    "    if (len(result[scenario].index)>1000) & (week!=1):\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\"))\n",
    "    else:\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\\n%H:%M\"))\n",
    "\n",
    "#Only plot the first week of data unless told otherwise\n",
    "        if week==1:\n",
    "            x_labels = result[scenario].index[0:672]\n",
    "            ax.stackplot(x_labels,result[scenario][[\"home_l1\",\"home_l2\",\"work_l1\",\"work_l2\",\"public_l2\",\"public_l3\"]][0:672].T)\n",
    "        else:\n",
    "            x_labels = result[scenario].index\n",
    "            ax.stackplot(x_labels,result[scenario][[\"home_l1\",\"home_l2\",\"work_l1\",\"work_l2\",\"public_l2\",\"public_l3\"]].T)\n",
    "        \n",
    "    plt.legend(['Home L1','Home L2','Work L1','Work L2','Public L2','DC Fast'],fontsize = 14,loc = 'upper left')\n",
    "    plt.xlabel('Date',size=18)\n",
    "    plt.ylabel('Grid Load [kW]',size=18)\n",
    "    plt.title('Fleet-wide Grid load: Scenario '+str(scenario),size=18)\n",
    "    plt.xticks(size=10)\n",
    "    plt.yticks(size=14)\n",
    "\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.xaxis_date()\n",
    "    ax.set_xlim([x_labels[0],x_labels[-1]])\n",
    "\n",
    "    ax.set_ylim([0,ymax*1.25])   \n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(8))\n",
    "\n",
    "    if filename == \"\":\n",
    "        filename = \"scen\"+str(scenario)+\"_gridLoad\"\n",
    "        \n",
    "    plt.savefig(os.path.join(os.path.curdir,'OutputData',filename))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "#Plotting for when there is no temperature data input and the output from API call is a single day's load profile for weekend and for weekday\n",
    "def notemp_loadPlotting(result,scenario, dow,filename = \"\"):\n",
    "    \n",
    "    fig = plt.figure(figsize = (12,5))\n",
    "    ax = plt.axes()\n",
    "    xaxis_labels = [(x * 15.0)/60.0 for x in range(0,96)]\n",
    "    ax.stackplot(xaxis_labels,result)\n",
    "    day_title = dow.split(\"_\")[0].capitalize()\n",
    "    \n",
    "    plt.legend(['Home L1','Home L2','Work L1','Work L2','Public L2','DC Fast'],fontsize = 14,loc = 'upper left')\n",
    "    plt.xlabel('Hour of Day',size=18)\n",
    "    plt.ylabel('Grid Load [kW]',size=18)\n",
    "    plt.title(day_title+' Fleet-wide Grid load: Scenario '+str(scenario),size=18)\n",
    "    plt.xticks(size=14)\n",
    "    plt.yticks(size=14)\n",
    "\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.set_xlim([0,24])\n",
    "\n",
    "    ax.set_ylim([0,ymax*1.25])   \n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(6)) \n",
    "    \n",
    "    if filename == \"\":\n",
    "        filename = \"scen\"+str(scenario)+\"_\"+day_title+\"_gridLoad.png\"\n",
    "        plt.savefig(os.path.join(os.path.curdir,\"OutputData\",filename))\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "##Stack Plot\n",
    "#plots data from startdate forward or from the first day of data forward if no startdate supplied\n",
    "#startdate in yyyy-mm-dd format\n",
    "#Plots forward numdays number of days (default is to plot one week)\n",
    "def csvPlotting(path,startdate = \"\",numdays = 7,filename = \"\"):\n",
    "    \n",
    "    result = pd.read_csv(path)\n",
    "    figlen = 12+len(result)/1000\n",
    "    fig = plt.figure(figsize = (figlen,7))\n",
    "    ax = plt.axes()\n",
    "\n",
    "#Only plot the first week of data unless told otherwise\n",
    "    if startdate==\"\":\n",
    "        x_labels = result.date[0:numdays*96]+ \" \"+ result.time[0:numdays*96]\n",
    "        x_labels = [datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\") for x in x_labels]\n",
    "        ax.stackplot(x_labels,result[[\"home_l1\",\"home_l2\",\"work_l1\",\"work_l2\",\"public_l2\",\"public_l3\"]][0:numdays*96].T)\n",
    "    else:\n",
    "        print(\"Assumed startdate in yyyy-mm-dd format...\")\n",
    "        try:\n",
    "            datetime.strptime(startdate,\"%Y-%m-%d\")\n",
    "        except:\n",
    "            print(\"Start date in wrong format. Need yyyy-mm-dd\")\n",
    "#Get index of first entry for start date (at time 00:00)       \n",
    "        startdate_idx = result[result.date==startdate].index[0]\n",
    "        enddate_idx = startdate_idx+numdays*96\n",
    "        x_labels = result.date[startdate_idx:enddate_idx]+ \" \"+ result.time[startdate_idx:enddate_idx]\n",
    "        x_labels = [datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\") for x in x_labels]\n",
    "        ax.stackplot(x_labels,result[[\"home_l1\",\"home_l2\",\"work_l1\",\"work_l2\",\"public_l2\",\"public_l3\"]][startdate_idx:enddate_idx].T)\n",
    "    \n",
    "    if (len(x_labels)>1000):\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\"))\n",
    "    else:\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d\\n%H:%M\"))\n",
    "    \n",
    "    plt.legend(['Home L1','Home L2','Work L1','Work L2','Public L2','DC Fast'],fontsize = 14,loc = 'upper left')\n",
    "    plt.xlabel('Date',size=18)\n",
    "    plt.ylabel('Grid Load [kW]',size=18)\n",
    "    plt.title('Fleet-wide Grid load: '+str(numdays)+\" days\",size=18)\n",
    "    plt.xticks(size=10)\n",
    "    plt.yticks(size=14)\n",
    "\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.xaxis_date()\n",
    "    ax.set_xlim([x_labels[0],x_labels[-1]])\n",
    "\n",
    "    ax.set_ylim([0,ymax*1.25])   \n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(8))\n",
    "\n",
    "    if filename == \"\":\n",
    "        filename = str(numdays)+\"days_gridLoad_plot\"\n",
    "    plt.savefig(os.path.join(os.path.curdir,filename))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d854e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
